# GenAI Cost Optimization

This document outlines the optimizations implemented to reduce GenAI token usage and costs in the Pet Clinic AI Agents demo.

## Issues Identified

Based on Application Signals analysis, the following cost drivers were identified:

### High Error Rates
- **Pet Clinic Agent**: 4.8% error rate (2,297 runtime errors)
- **Nutrition Agent**: 9.8% error rate (2,301 errors) 
- **Total**: 4,659 errors across GenAI services
- **Impact**: Failed requests consume tokens but provide no value

### Inefficient Token Usage
- **Input tokens**: 99M+ tokens across agents
- **Output tokens**: 16.9M+ tokens
- **Invocations**: 70,978 total calls
- **Issue**: Verbose prompts and excessive context

### Configuration Problems
- Invalid ARN errors in agent calls
- Missing account IDs in agent runtime calls
- Throttling due to lack of rate limiting
- Legacy model usage (anthropic.claude-v2)

## Optimizations Implemented

### 1. Error Rate Reduction

#### Nutrition Agent (`pet_clinic_ai_agents/nutrition_agent/nutrition_agent.py`)
- **Reduced error simulation**: From 35% to 5% error rate
- **Simplified error types**: Removed timeout and network errors
- **Added rate limiting**: 100ms minimum interval between requests
- **Expected savings**: ~30% reduction in failed token consumption

#### Primary Agent (`pet_clinic_ai_agents/primary_agent/pet_clinic_agent.py`)
- **Added retry logic**: Exponential backoff for failed requests
- **Response caching**: 5-minute TTL to avoid duplicate calls
- **Throttling handling**: Proper error handling for rate limits
- **Expected savings**: ~15% reduction from avoiding retries

### 2. Token Usage Optimization

#### Prompt Optimization
- **Nutrition Agent**: Reduced system prompt from 500+ to 200 tokens
- **Primary Agent**: Compressed instructions while maintaining functionality
- **Expected savings**: ~25% reduction in input tokens per request

#### Request Deduplication
- **Traffic Generator**: Added MD5-based request caching
- **Cache TTL**: 5 minutes to balance freshness and efficiency
- **Expected savings**: ~20% reduction from duplicate requests

### 3. Traffic Pattern Improvements

#### Traffic Generator (`cdk/agents/lambda/traffic-generator/traffic_generator.py`)
- **Reduced request volume**: From 20 to 10 requests per invocation
- **Lower nutrition query ratio**: From 75% to 60%
- **Rate limiting**: 100ms between requests
- **Retry logic**: Exponential backoff for failed requests
- **Expected savings**: ~50% reduction in total requests

## Expected Cost Savings

| Optimization | Expected Reduction |
|--------------|-------------------|
| Error elimination | ~10% |
| Prompt optimization | ~25% |
| Request caching | ~20% |
| Traffic reduction | ~50% |
| **Total Expected** | **~60-70%** |

## Monitoring Recommendations

1. **Track error rates** using Application Signals SLOs
2. **Monitor token usage** per request to identify outliers
3. **Set up alerts** for high error rates or token consumption spikes
4. **Regular review** of prompt efficiency and caching hit rates

## Additional Recommendations

### Short-term
1. Update deprecated models (claude-v2 â†’ claude-3.5-haiku)
2. Fix agent configuration errors (invalid ARNs)
3. Implement request deduplication at the API gateway level

### Long-term
1. Implement semantic caching for similar queries
2. Add prompt compression techniques
3. Consider fine-tuned models for specific use cases
4. Implement dynamic rate limiting based on usage patterns

## Implementation Notes

- All changes maintain backward compatibility
- Error handling improvements provide better user experience
- Caching mechanisms are memory-efficient with automatic cleanup
- Rate limiting prevents service overload while maintaining responsiveness